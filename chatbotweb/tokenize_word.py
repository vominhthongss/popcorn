from underthesea import word_tokenize
from underthesea import classify
import re
import traceback
def normalize_text(text):

        #Loแบกi bแป cรกc kรฝ tแปฑ kรฉo dรi: vd: hayyyyyyy
        #text = re.sub(r'([A-Z])\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)

        # Chuyแปn cรกc chแปฏ hoa thรnh chแปฏ thฦฐแปng
        text = text.lower()

        #Chuแบฉn hรณa tiแบฟng Viแปt, tiแบฟng Anh, xแปญ lรฝ emoj
        replace_list = {
            'รฒa': 'oร', 'รณa': 'oรก', 'แปa': 'oแบฃ', 'รตa': 'oรฃ', 'แปa': 'oแบก', 'รฒe': 'oรจ', 'รณe': 'oรฉ','แปe': 'oแบป',
            'รตe': 'oแบฝ', 'แปe': 'oแบน', 'รนy': 'uแปณ', 'รบy': 'uรฝ', 'แปงy': 'uแปท', 'ลฉy': 'uแปน','แปฅy': 'uแปต', 'uแบฃ': 'แปงa',
            'aฬ': 'แบฃ', 'รดฬ': 'แป', 'uยด': 'แป','รดฬ': 'แป', 'รดฬ': 'แป', 'รดฬ': 'แป', 'รขฬ': 'แบฅ', 'รขฬ': 'แบซ', 'รขฬ': 'แบฉ',
            'รขฬ': 'แบง', 'oฬ': 'แป', 'รชฬ': 'แป','รชฬ': 'แป', 'ฤฬ': 'แบฏ', 'uฬ': 'แปง', 'รชฬ': 'แบฟ', 'ฦกฬ': 'แป', 'iฬ': 'แป',
            'eฬ': 'แบป', 'รk': u' ร ','aห': 'ร', 'iห': 'รฌ', 'ฤยด': 'แบฏ','ฦฐฬ': 'แปญ', 'eห': 'แบฝ', 'yห': 'แปน', 'aยด': 'รก',
            ':))': '  positive ', ':)': ' positive ',' vl ': ' negative ',
            'kg ': u' khรดng ','not': u' khรดng ', u' kg ': u' khรดng ',' kh ':u' khรดng ','kรด':u' khรดng ','ko':u' khรดng ','hok':u' khรดng ',
            ' kp ': u' khรดng phแบฃi ',u' kรด ': u' khรดng ', '"ko ': u' khรดng ', u' ko ': u' khรดng ', u' k ': u' khรดng ', 'khong': u' khรดng ', u' hok ': u' khรดng ',
            'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',
            ' lol ': ' negative ',' cc ': ' negative ','cute': u' dแป thฦฐฦกng ','huhu': ' negative ', ' vs ': u' vแปi ', 'wa': ' quรก ', 'wรก': u' quรก', 'j': u' gรฌ ', 'โ': ' ',
            ' sz ': u' cแปก ', 'size': u' cแปก ', u' ฤx ': u' ฤฦฐแปฃc ', 'dk': u' ฤฦฐแปฃc ', 'dc': u' ฤฦฐแปฃc ', 'ฤk': u' ฤฦฐแปฃc ',
            'ฤc': u' ฤฦฐแปฃc ', 'gud': u' tแปt ','god': u' tแปt ','wel done':' tแปt ', 'good': u' tแปt ', 'gรบt': u' tแปt ',
            'sแบฅu': u' xแบฅu ','gut': u' tแปt ', u' tot ': u' tแปt ', u' nice ': u' tแปt ', 'perfect': 'rแบฅt tแปt', 'bt': u' bรฌnh thฦฐแปng ',
            'time': u' thแปi gian ', 'qรก': u' quรก ', u' m ': u' mรฌnh ', u' mik ': u' mรฌnh ',
            'รชฬ': 'แป', 'excellent': 'xuแบฅt sแบฏc', 'quality': 'chแบฅt lฦฐแปฃng','chat':' chแบฅt ', 'excelent': 'hoรn hแบฃo', 'bad': 'tแป','sad': ' tแป ',
            'shit': u' dแป แบนt ',u' zแป ': u' vแบญy ','beautiful': u' ฤแบนp tuyแปt vแปi ',u'bjo':u' bao giแป ',
            'thik': u' thรญch ',' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rแบฅt ',
            'dep': u' ฤแบนp ',u' xau ': u' xแบฅu ','nice': u' hay ', u'qแปงa': u' quแบฃ ',
            'iu': u' yรชu ','fake': u' giแบฃ mแบกo ', '><': u' positive ',
            ' por ': u' tแป ',' poor ': u' tแป ',}
        for k, v in replace_list.items():
            text = text.replace(k, v)
        #remove nแปt nhแปฏng kรฝ tแปฑ thแปซa thรฃi
        text = text.replace(u'"', u' ')
        text = text.replace(u'๏ธ', u'')
        text = text.replace('๐ป','')
        text = word_tokenize(text, format="text")
        return text
# def replace_list(text):
#   replace_list = { ' tks ': u' cรกm ฦกn ', 'thks': u' cรกm ฦกn ', 'thanks': u' cรกm ฦกn ', 'ths': u' cรกm ฦกn ', 'thank': u' cรกm ฦกn ', 'shop': u' cแปญa hรng ', 'sp': u' sแบฃn phแบฉm ',
#  '๐': ' negative ', '๐': ' positive ', '๐': ' negative ', '๐': ' positive ', '๐': ' positive ',
#   '๐': ' positive ', '๐ค': ' negative ', '๐': ' positive ', '๐': ' positive ', '๐': ' positive ',
#   '?':'','.': '',',': '',}
#   for k, v in replace_list.items():
#             text = text.replace(k, v)
#   return text

def clean(text):
  return word_tokenize(normalize_text(text), format="text")

def get_list(text):
  list_word=word_tokenize(clean(text))
  return list_word
  
def classify_word(text):
  return classify(text)
